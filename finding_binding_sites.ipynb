{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding the binding sites\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#\n",
    "#          Imports\n",
    "\n",
    "import string   # Module that helps with string methods. Used here\n",
    "                # for replacing a substring with the capitalized\n",
    "                # version of that substring.\n",
    "import os       # Used for checking if a filepath exists\n",
    "\n",
    "#\n",
    "#\n",
    "########################################################################\n",
    "#\n",
    "#    Pre-defined variables\n",
    "\n",
    "# This dictionary contains keys that are file extensions\n",
    "# and values of dictionaries with information on which\n",
    "# column of the data file will have the desired information.\n",
    "                   # narrowPeak files (from MACS3):\n",
    "peakfile_formats ={\"narrowPeak\" : {\"chrom\" : \"1\",  # Chromosome, column1\n",
    "                                   \"start\" : \"2\",  # Region start, column2\n",
    "                                   \"end\"   : \"3\"}, # Region end, column3\n",
    "                   # Excel spreadsheet files (from MACS3)\n",
    "                   \"xls\"        : {\"chrom\" : \"1\",  # Chromosome, column1\n",
    "                                   \"start\" : \"2\",  # Region start, column2\n",
    "                                   \"end\"   : \"3\"}} # Region end, column3\n",
    "\n",
    "\n",
    "# This is a list of strings containing the single letter identifiers\n",
    "# for each nucleotide. \"N\" is the symbol for an unidentified nucleotide\n",
    "# in a sequence.\n",
    "nukes = [\"A\", \"T\", \"C\", \"G\", \"N\"]\n",
    "\n",
    "#\n",
    "#\n",
    "########################################################################\n",
    "#\n",
    "#    Helper Functions\n",
    "\n",
    "def str_a_list(a_list):\n",
    "    \"\"\"\n",
    "    Given a list, return all elements of the list\n",
    "    as a single string.\n",
    "    \"\"\"\n",
    "    # Assure that the user gave a list object\n",
    "    assert type(a_list) == list, \"The input was not a list.\"\n",
    "    # Initialize the output string\n",
    "    outstr = \"\"\n",
    "    # Loop over the elements in the list\n",
    "    for element in a_list:\n",
    "        # Update the outstr with the new element at the end\n",
    "        outstr = f\"{outstr}{element}\"\n",
    "    # Return the outstr variable\n",
    "    return outstr\n",
    "\n",
    "def reverse_a_str(a_string):\n",
    "    \"\"\"\n",
    "    Given a string, return that string with the\n",
    "    characters in reverse order\n",
    "    \"\"\"\n",
    "    # Assure that the user input a string\n",
    "    assert type(a_string) == str, \"The input was not a string\"\n",
    "    # Turn the string into a list. Each character will be\n",
    "    # a unique element of the list\n",
    "    str_list = list(a_string)\n",
    "    # Use list comprehension to iterate over the elements\n",
    "    # of the list in reverse order. \n",
    "    # Note: a_list[-i] gets the ith element from the end of the list. \n",
    "    str_list = [str_list[-i] for i in range(1,len(str_list) + 1)]\n",
    "    # Use the str_a_list() function to turn the list into a\n",
    "    # string and return that string.\n",
    "    return str_a_list(str_list)\n",
    "\n",
    "def add_newline_every_x_chars(string, x = 80):\n",
    "    \"\"\"\n",
    "    Given a string and an integer number x (default is 80),\n",
    "    return the string with a newline character every x \n",
    "    \"\"\"\n",
    "    # Assuer that the user input a string and an integer\n",
    "    assert type(string) == str, f\"The input {string} is not a string\"\n",
    "    assert type(x) == int, f\"The input {x} is not an integer type\"\n",
    "    # Assure that the value of x is less than or equal to\n",
    "    # the length of the string\n",
    "    assert len(string) >= x, f\"The distance {x} is greater than the size of the string\"\n",
    "    # Initialize the newstring variable as an empty string\n",
    "    newstring = \"\"\n",
    "    # Initialize the count variable as 0\n",
    "    count=0\n",
    "    # Loop over the characters in the string\n",
    "    for char in string:\n",
    "        # If the count is zero\n",
    "        if count == 0:\n",
    "            # Then update the newstring with this character\n",
    "            newstring=f\"{newstring}{char}\"\n",
    "            # and increase the count\n",
    "            count+=1\n",
    "        # Or if the count is not a multiple of the x integer\n",
    "        # (count % x is the modular operator and returns the\n",
    "        # remainder of dividing count by x)\n",
    "        elif count % x != 0:\n",
    "            # Then update the newstring variable\n",
    "            newstring=f\"{newstring}{char}\"\n",
    "            # and increase the count\n",
    "            count+=1\n",
    "        # Otherwise, the count is a multiple of x. Thus,\n",
    "        else:\n",
    "            # add the current character and a newline character\n",
    "            # to the newstring\n",
    "            newstring=f\"{newstring}{char}\\n\"\n",
    "            # and reset the count to zero\n",
    "            count=0\n",
    "    # At the end, return the newstring variable.\n",
    "    return newstring\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#      Frequency matrix calculator: Usage is optional\n",
    "\n",
    "def check_motif_lengths(motifs_list):\n",
    "    \"\"\"\n",
    "    Given a list of (motif, strand) tuples, check the length of the motifs\n",
    "    and partition them based on their lengths\n",
    "    \"\"\"\n",
    "    # Initialize the dictionary to hold partitions\n",
    "    motifs_dict = {}\n",
    "    # Loop over the motifs in the motif list\n",
    "    for motif in motifs_list:\n",
    "        # Check to see if the motif length is in the motifs_dict key\n",
    "        # values already. If not\n",
    "        if f\"{len(motif[0])}\" not in motifs_dict.keys():\n",
    "            # Then initialize the motifs dictionary with this key\n",
    "            # and a list as the value\n",
    "            motifs_dict[f'{len(motif[0])}'] = [motif]\n",
    "        # If the length of the motif is already a key in the dictionary\n",
    "        else:\n",
    "            # Then simply update the list with this sequence\n",
    "            motifs_dict[f'{len(motif[0])}'].append(motif)\n",
    "    # Once the loop is completed, return the motifs dictionary.\n",
    "    return motifs_dict\n",
    "\n",
    "def get_frequency_dict(motifs_list):\n",
    "    \"\"\"\n",
    "    Given a list of (motif, strand) tuples, return a dictioanry\n",
    "    counting the frequency of each nucleotide in each position\n",
    "    of the sequence\n",
    "    \"\"\"\n",
    "    assert type(motifs_list) == list, \"The motifs should be a list of tuples...\"\n",
    "    for motif in motifs_list:\n",
    "        assert type(motif) == tuple, \"The motifs should be a list of tuples...\"\n",
    "        assert type(motif[0]) == str, \"The zeroeth element of each tyuple should be a str type\"\n",
    "        assert motif[1] == \"+\" or motif[1] == \"-\", \"The first element of each tuple should denote strandedness: + or -\"\n",
    "    # Initialize the frequency_dict variable with the keys as\n",
    "    # nucleotides and empty dictionaries as values.\n",
    "    frequency_dict = {\"A\": {},\n",
    "                      \"G\": {},\n",
    "                      \"T\": {},\n",
    "                      \"C\": {}}\n",
    "    # Loop over the motifs in the motifs_list\n",
    "    for motif in motifs_list:\n",
    "        # Loop over the siz of the motifs\n",
    "        for i in range(len(motif[0])):\n",
    "            # Loop over the keys and values of the frequency dictionary\n",
    "            for key, value in frequency_dict.items():\n",
    "                # If the position is not already a key in the subdictionary,\n",
    "                if f\"{i}\" not in value.keys():\n",
    "                    # and if the current nucleotide in the sequence is\n",
    "                    # the key in the frequency_dict\n",
    "                    if motif[0][i].upper() == key:\n",
    "                        # Then initialize the position key with value 1\n",
    "                        # in the value subdictionary\n",
    "                        value[f\"{i}\"] = 1\n",
    "                    # Otherwise, just initialize this subdictionary\n",
    "                    else:\n",
    "                        # At count zero\n",
    "                        value[f\"{i}\"] = 0\n",
    "                # Or if the position is already a key in the subdictionary\n",
    "                elif f\"{i}\" in value.keys():\n",
    "                    # Then if the current nucleotide is the same as the\n",
    "                    # frequency_dict key\n",
    "                    if motif[0][i].upper() == key:\n",
    "                        # Then increase the count by 1\n",
    "                        value[f\"{i}\"] += 1\n",
    "    # Save the total number of sequences in this list in the frequency dict\n",
    "    frequency_dict['total'] = len(motifs_list)\n",
    "    # And return the frequency dictionary\n",
    "    return frequency_dict\n",
    "\n",
    "def calculate_probabilities(frequency_dict):\n",
    "    \"\"\"\n",
    "    Given a frequency dictionary, return a list of lists where\n",
    "    the zeroeth element is the position of an A or T in the sequence\n",
    "    and the first element is the probability that the A or T is in\n",
    "    that position (calculated using Laplace's Definition of Probability)\n",
    "    \"\"\"\n",
    "    assert type(frequency_dict) == dict, \"The frequency_dict argument should be a dictionary...\"\n",
    "    needed_keys = [\"A\", \"T\", \"C\", \"G\", \"total\"]\n",
    "    for key in needed_keys:\n",
    "        assert key in frequency_dict.keys(), f\"{key} is not a key in the frequency dictioanry...\"\n",
    "    # Initialize the at_posittions list using list comprehension.\n",
    "    # The keys of the subdictionary are position strings, and the\n",
    "    # counts should be initialized to zero\n",
    "    at_positions = [[key, 0] for key in frequency_dict[\"A\"].keys()]\n",
    "    # Loop over the position numbers for the sequence, which are the\n",
    "    # keys of a (any of the) subdictionaries in frequency_dict. This\n",
    "    # must happen first, as we want the number of As or Ts in the\n",
    "    # num(th) position of the sequence.  \n",
    "    for num in frequency_dict[\"A\"].keys():\n",
    "        # Loop over the keys and values in the frequency_dict\n",
    "        for key, value in frequency_dict.items():\n",
    "            # IF the key is total then continue, this is just for probabilities\n",
    "            if key == \"total\":\n",
    "                continue\n",
    "            # But if the key is A or T,\n",
    "            elif key == \"A\" or key == \"T\":\n",
    "                # Then loop over the sublists in at_positions\n",
    "                for sublist in at_positions:\n",
    "                    # If the position indicator in the sublist is the same\n",
    "                    # as the num(th) position (the one we're looping over)\n",
    "                    if sublist[0] == num:\n",
    "                        # then increase the count for that numth element of the list\n",
    "                        sublist[1] += value[num]\n",
    "    # Use list comprehension to calculate the probability of an A or T being\n",
    "    # in the position.\n",
    "    at_positions = [[sublist[0], sublist[1]/frequency_dict['total']] for sublist in at_positions]\n",
    "    # and return these probabilities\n",
    "    return at_positions\n",
    "\n",
    "def get_parting_list(at_position_probs, threshold = 0.07):\n",
    "    \"\"\"\n",
    "    Given the AT position probabilities (list of lists) and a threshold\n",
    "    (default is 0.07), return the positions to partition the motifs on.\n",
    "    \n",
    "    The input list to this function is the output from calculate_probabilities\n",
    "    \"\"\"\n",
    "    # Assure that all of the inputs are properly formatted\n",
    "    assert type(at_position_probs) == list, \"The at_position_probs argument should be a list..\"\n",
    "    for pos in at_position_probs:\n",
    "        assert type(pos) == list, \"Each element in the at_position_probs list should also be a list...\"\n",
    "        assert len(pos) == 2, \"The subslists should each only be two elements....\"\n",
    "        assert type(pos[0]) == str, \"The zeroeth element of each list should be a string...\"\n",
    "        assert type(pos[1]) == float or type(sublist[1]) == int, \"The first element of each sublist should be a number...\"\n",
    "    assert type(threshold) == float and threshold >= 0 and threshold <= 0.1, \"The threshold should be a float between 0 and 0.1\"\n",
    "    # Initialize the partition_positions list\n",
    "    partition_positions = []\n",
    "    # Loop over the positions in the at_position_probs list\n",
    "    for position in at_position_probs:\n",
    "        # If the probability of a position is within the thresholded\n",
    "        # value\n",
    "        if position[1] <= 0.5+threshold and position[1] >= 0.5-threshold:\n",
    "            # Then add that position to the list.\n",
    "            partition_positions.append(int(position[0]))\n",
    "    # Then return the parition_positions list.\n",
    "    return partition_positions\n",
    "            \n",
    "def get_frequeny_matrix_lines(frequency_dict, tf_name = \"TF\"):\n",
    "    \"\"\"\n",
    "    Given a frequency dictionary (created by the get_frequency_dict function),\n",
    "    return a list of lines in JASPAR format to display the frequency\n",
    "    matrix for the sequence.\n",
    "    \"\"\"\n",
    "    assert type(frequency_dict) == dict, \"The frequency dictionary should be a dictionary...\"\n",
    "    assert type(tf_name) == str, \"The transcription factor name should be a string..\"\n",
    "    # Initialize the first line of the file, which is the TF name with a carrot\n",
    "    first_line = [f\">{tf_name}\\n\"]\n",
    "    # Initialize a list to hold the lines to file\n",
    "    lines_list = []\n",
    "    # Loop over the keys and values in the frequency_dict\n",
    "    for key, value in frequency_dict.items():\n",
    "        # If the key 'total' shows up, just continue. That stores the total\n",
    "        # number of sequences\n",
    "        if key == 'total':\n",
    "            continue\n",
    "        # Initialize the line using string formatting. The keys are nucleotides,\n",
    "        # and the :<3 syntax means \"left oriented, allow 3 spaces for the string\"\n",
    "        line = f\"{key:<3}[\"\n",
    "        # Get the positions list using list comprehension (positions in sequence\n",
    "        # are keys in each subdictionary in frequency_dict)\n",
    "        positions = [int(pos) for pos in value.keys()]\n",
    "        # Sort the positions in ascending order\n",
    "        positions = sorted(positions)\n",
    "        # Loop over the positions in the positions list\n",
    "        for pos in positions:\n",
    "            # and update the line with the count (subdictionary value at position\n",
    "            # key), right oriented with 6 characters allowed for the numbers.\n",
    "            line = f\"{line}{value[str(pos)]:>6}\"\n",
    "        # Once the loop ends, add the ending ] character and a newline character\n",
    "        line = f\"{line} ]\\n\"\n",
    "        # and add the line to the list\n",
    "        lines_list.append(line)\n",
    "    # Once all of the lines are defined, sort the lines based on the first character\n",
    "    # in each line. \n",
    "    lines_list = sorted(lines_list, key = lambda x: x[0])\n",
    "    # And return the list of the first_line + the lines_list\n",
    "    return first_line + lines_list\n",
    "\n",
    "\n",
    "def partition_by_motif_length(motifs_dict):\n",
    "    \"\"\"\n",
    "    Given a motifs dictionary, return a list of the\n",
    "    motif lists partitioned on length.\n",
    "    \"\"\"\n",
    "    # If only one item is in the motifs dictionary\n",
    "    if len(motifs_dict.keys()) == 1:\n",
    "        # Then get the key for that item\n",
    "        keylist = list(motifs_dict.keys())\n",
    "        # and return it\n",
    "        return [motifs_dict[keylist[0]]]\n",
    "    # Otherwise,\n",
    "    else:\n",
    "        # Return them all.\n",
    "        return [value for key,value in motifs_dict.items()]\n",
    "\n",
    "def get_partition_sites(sites_file,\n",
    "                        threshold = 0.07,\n",
    "                        tf_name = \"TF\"):\n",
    "    \"\"\"\n",
    "    Given a sites file, a threshold, and a transcription factor name,\n",
    "    return a list of tuples, where each tuple contains a motif list and\n",
    "    the equaly likely nucleotides.\n",
    "    \"\"\"\n",
    "    # GEt the directory path to the file\n",
    "    directory = os.path.split(os.path.realpath(sites_file))[0]\n",
    "    # Get the motifs from the sites file\n",
    "    annoted_motifs = parse_sites_file(sites_file)\n",
    "    # Check the lengths of the motifs\n",
    "    partitioned_motif_list = check_motif_lengths(annoted_motifs)\n",
    "    # Partition the motif by length\n",
    "    partitioned_motif_list = partition_by_motif_length(partitioned_motif_list)\n",
    "    # Set the motif counter\n",
    "    motif_counter = 0\n",
    "    # Initialize the motif list\n",
    "    motif_list = []\n",
    "    # loop over the sublists in the paritioned motif list\n",
    "    for sublist in partitioned_motif_list:\n",
    "        # Get the frequency dictionary\n",
    "        frequency = get_frequency_dict(sublist)\n",
    "        # Calculate the probability of A and T\n",
    "        prob_list = calculate_probabilities(frequency)\n",
    "        # get the partition positions based on the probability of A and T\n",
    "        partition_positions = get_parting_list(prob_list, threshold = threshold)\n",
    "        # Add the sublist and partition positions to the list\n",
    "        motif_list.append((sublist, partition_positions))\n",
    "        # GEt the lines for the jaspar style frequency matrix\n",
    "        freq_matrix_lines = get_frequeny_matrix_lines(frequency, tf_name)\n",
    "        # Write the frequency matrix\n",
    "        write_output_file(freq_matrix_lines, f'{directory}/motif_{motif_counter}.jaspar')\n",
    "        # Increase the count\n",
    "        motif_counter += 1\n",
    "    # Return the motifs list. \n",
    "    return motif_list\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#         Functions for making potential binding site lists\n",
    "\n",
    "def parse_sites_file(a_sites_file,\n",
    "                     nucleotides_list = nukes):\n",
    "    \"\"\"\n",
    "    Given a .sites file (from JASPAR, download the FASTA version of\n",
    "    transcription factor binding sites) and a list of nucleotide strings,\n",
    "    return a list of the TF binding sites.\n",
    "    \n",
    "    NOTE: The .sites files are short form FASTA files, where the binding\n",
    "    sites are all capitalized and the rest of the sequence is not.\n",
    "    \n",
    "    The region lines of a JASPAR sites file have the following format:\n",
    "    >gs_chrNUM:reg_start-reg_end(plus/minus_strand)\n",
    "    \n",
    "    an example:\n",
    "    >dm_chr2L:5980922-5980936(+)\n",
    "    \"\"\"\n",
    "    # Assure that the file name is a string\n",
    "    assert type(a_sites_file) == str, \"The name of the .sites file should be a string\"\n",
    "    # And that it exists\n",
    "    assert os.path.exists(a_sites_file), f\"The file {a_sites_file} does not exist...\"\n",
    "    # Initialize the list to hold the TF binding site strings.\n",
    "    site_strings = []\n",
    "    # Open and read the sites file\n",
    "    with open(a_sites_file, 'r') as f:\n",
    "        # Initialize a string for a site. This will be updated with\n",
    "        # each binding site as the file is read.\n",
    "        site_builder = \"\"\n",
    "        # Initialize the go variable. This is used to keep the while loop\n",
    "        # going, and will be set to False when there are no more lines\n",
    "        # in the file.\n",
    "        go = True\n",
    "        # Start a while loop, using go as the boolean condition for the loop\n",
    "        while go:\n",
    "            # Read a line of the file, save it as line\n",
    "            line = f.readline()\n",
    "            # Try to get the zeroeth character in the line. Will fail if the\n",
    "            # line is empty, i.e. the file has no more lines.\n",
    "            try:\n",
    "                line[0]\n",
    "            # IF this does fail, set go to False so the while loop will stop\n",
    "            except:\n",
    "                go = False\n",
    "            # If this does not fail, then check the line type.\n",
    "            else:\n",
    "                # If the zeroeth character of the line is a >, you're on a new region.\n",
    "                # if the site builder has not been initialized, then get the direction\n",
    "                # of the sequence from the line.\n",
    "                if line[0] == \">\" and site_builder == \"\":\n",
    "                    # Then save the strand direction of the upcoming sequence\n",
    "                    direction = line[-3]\n",
    "                # Or if the 0th element is a > and the site builder is not an empty string\n",
    "                elif line[0] == \">\" and site_builder != \"\":\n",
    "                    # Then save the previuosly built transcription factor and strand direction\n",
    "                    # as a tuple to the site_strings list\n",
    "                    site_strings.append((site_builder, direction))\n",
    "                    # And reset the site_builder variable to the empty string\n",
    "                    site_builder = \"\"\n",
    "                    # and save the strand direction of the next region\n",
    "                    direction = line[-3]\n",
    "                # If there is no > character, then we are at a sequence section!\n",
    "                else:\n",
    "                    # Make a list of all the nucleotides in the sequence that are also\n",
    "                    # in the nucleotide list. Nucleotide list is assumed to be capitalized\n",
    "                    site_list = [letter for letter in line if letter in nucleotides_list]\n",
    "                    # Update the site_builder variable with these letters, as a string\n",
    "                    site_builder += str_a_list(site_list)\n",
    "        # At the end, add the last site string to the list\n",
    "        site_strings.append((site_builder, direction))\n",
    "        # Once you have found all of the TF binding sites, the while loop will end and we\n",
    "        # can close the file.\n",
    "        f.close()\n",
    "    # And return the list of TF binding site strings.\n",
    "    return site_strings     \n",
    "\n",
    "def minus_to_plus(binding_site_list):\n",
    "    \"\"\"\n",
    "    Given a list of binding sites from a JASPAR sites file,\n",
    "    return a list of all possible + strand sequences, and all\n",
    "    possible minus strand sequences. \n",
    "    \n",
    "    NOTE: A sequence on the minus (-) strand will show up as\n",
    "    the reverse complement on the plus strand. Since the genome\n",
    "    FASTA files are only the + strand, we need to convert\n",
    "    all the - strand sequences into + strand sequences. Similarly,\n",
    "    we can check the minus strands for + strand like sequences by\n",
    "    finding the reverse complement of the + strand sequences. Therefore,\n",
    "    all combinations of + and - strand sequences are found.\n",
    "    \n",
    "    The revere part is not done in this function, that is saved for\n",
    "    after partitioning of the sequences.\n",
    "    \"\"\"\n",
    "    assert type(binding_site_list) == list, \"The input needs to be a list\"\n",
    "    for site in binding_site_list:\n",
    "        assert type(site) == tuple, \"The input list should only contain strings tuples\"\n",
    "        assert len(site) == 2, \"The tuples should only have two elements: (motif_string, +) or (motif_string, -)\"\n",
    "        assert type(site[0]) == str, \"The motif should be a string\"\n",
    "        assert \"+\" in site[1] or \"-\" in site[1], \"The first element of the tuple should be + or -\"\n",
    "    # nucleotide complements in DNA strands\n",
    "    pairs = {\"A\" : \"T\",\n",
    "             \"T\" : \"A\",\n",
    "             \"G\" : \"C\",\n",
    "             \"C\" : \"G\",\n",
    "             \"N\" : \"N\"}\n",
    "    # Initialize the plus and minus strand lists\n",
    "    all_possible_plus = []\n",
    "    all_possible_minus = []\n",
    "    # Loop over the motifs in the binding_site\n",
    "    for motif in binding_site_list:\n",
    "        # Initialize the string_manip variable. The name is a joke\n",
    "        # from pokemon speedrunning. When they manipulate the computer\n",
    "        # in some way, they call it a \"manip\"\n",
    "        string_manip = \"\"\n",
    "        # If the first element of the motif tuple is a +, that\n",
    "        # means that this motif is on the + strand\n",
    "        if motif[1] == \"+\":\n",
    "            # So add this motif to the + strand list\n",
    "            all_possible_plus.append(motif[0])\n",
    "            # and loop over all the letters int he motif\n",
    "            for letter in motif[0]:\n",
    "                # and update the string_manip variable with the\n",
    "                # complement strand\n",
    "                string_manip = f\"{string_manip}{pairs[letter]}\"\n",
    "            # And add the complement to the minus strand list.\n",
    "            all_possible_minus.append(string_manip)\n",
    "        # Or if the first element of the motif tuple\n",
    "        # is a -, then this is a - strand sequence.\n",
    "        elif motif[1] == \"-\":\n",
    "            # So add this motif to the plus strand list\n",
    "            all_possible_plus.append(motif[0])\n",
    "            # and loop over all the letters int he motif\n",
    "            for letter in motif[0]:\n",
    "                # and update the string_manip variable with the\n",
    "                # complement strand\n",
    "                string_manip = f\"{string_manip}{pairs[letter]}\"\n",
    "            # And add the complement to the minus strand list.\n",
    "            all_possible_minus.append(string_manip)\n",
    "    # At the end, return the lists of all possible plus and minus motifs\n",
    "    return all_possible_plus, all_possible_minus\n",
    "\n",
    "def partition_on_unassigned_nucs(motif_list,\n",
    "                                 partitions_list):\n",
    "    \"\"\"\n",
    "    Given a list of motifs and a list of integers that specify the\n",
    "    equally likely nucleotide positions in the motifs, return\n",
    "    a list of lists, where each sublist contains strings split at\n",
    "    the indicated positions.\n",
    "    \"\"\"\n",
    "    # Assure that the given inputs are the proper types\n",
    "    assert type(motif_list) == list, \"The motifs should be in a list...\"\n",
    "    for motif in motif_list:\n",
    "        assert type(motif) == str, \"Each motif needs to be type str\"\n",
    "    assert type(partitions_list) == list, \"The partition positions should be in a list\"\n",
    "    for location in partitions_list:\n",
    "        assert type(location) == int, \"Each partition position should be an integer.\"\n",
    "    # Get the size of a motif, minus 1. This is the index of the last element in the\n",
    "    # motifs list\n",
    "    size = len(motif_list[0]) - 1\n",
    "    # If 0 is not in the partitions_list\n",
    "    if 0 not in partitions_list:\n",
    "        # Then add zero to the partitions_list\n",
    "        partitions_list.append(0)\n",
    "    # If the size of the motif is not in the partitions list,\n",
    "    if size not in partitions_list:\n",
    "        # Then add the size to the list as well.\n",
    "        partitions_list.append(size)\n",
    "    # And sort the partitions list. This list is used to slice the motifs, so we\n",
    "    # need to have the beginning, the end, and the partition points in between\n",
    "    # in order for the following loop to function. Also they need to be in\n",
    "    # ascending order.\n",
    "    partitions_list = sorted(partitions_list)\n",
    "    # Inititalize the parted_motifs list. This will hold all of the lists of \n",
    "    # partitioned motifs\n",
    "    parted_motifs = []\n",
    "    # Loop over the sequences in the motif list.\n",
    "    for sequence in motif_list:\n",
    "        # Initialize the sequence parts list. This will hold the parts of a\n",
    "        # specific sequence\n",
    "        seq_parts = []\n",
    "        # Loop over the number of elements in the partitions list, minus 1.\n",
    "        for i in range(len(partitions_list)-1):\n",
    "            # If the ith element of the partitions list is zero\n",
    "            if partitions_list[i] == 0:\n",
    "                # Then this we need to slice the string from beginning:first_location\n",
    "                # and add that substring to the sequence parts list.\n",
    "                seq_parts.append(sequence[partitions_list[i]:partitions_list[i+1]])\n",
    "            # Or if the i+1(th) element of the list is the length of the sequence\n",
    "            elif partitions_list[i+1] == len(sequence)-1:\n",
    "                # Then we need to slice the string from last_part:end\n",
    "                seq_parts.append(sequence[partitions_list[i]+1:])\n",
    "            # If neither the beginning nor the end cases are happening,\n",
    "            else:\n",
    "                # Then we are in the middle and we need to slice the string as\n",
    "                # (location_i)+1 : (location_i+1)-1\n",
    "                # because location_i needs to be excluded, and so does location_i+1.\n",
    "                # String slicing tutorial:\n",
    "                # a = \"12345\" ->   a[1:3]   ->   \"23\" (keeps elements 1 and 2, excludes 3)\n",
    "                seq_parts.append(sequence[partitions_list[i]+1:partitions_list[i+1]])\n",
    "        # Once the sequence has been partitioned, add the partitioned sequence to the main list\n",
    "        parted_motifs.append(seq_parts)\n",
    "    # And at the end, return the parted_motifs list\n",
    "    return parted_motifs\n",
    "\n",
    "def bin_the_parts(seqs_split_on_null):\n",
    "    \"\"\"\n",
    "    Given the list of sequences split on the equally likely nucleotides,\n",
    "    return the parts, binned by their position relative to the original\n",
    "    sequence.\n",
    "    \"\"\"\n",
    "    # Assure the inputs are in the correct format.\n",
    "    assert type(seqs_split_on_null) == list, \"The input should be a list\"\n",
    "    for item in seqs_split_on_null:\n",
    "        assert type(item) == list or type(item) == tuple, \"The items in the input list should also be lists...\"\n",
    "        for string in item:\n",
    "            assert type(string) == str, \"The input lists should contain lists, which should contain strings......\"\n",
    "    # Use list comprehension to make a list of lists, where each list\n",
    "    # contains the ith part of split sequences\n",
    "    bin_list = [[parts[i] for parts in seqs_split_on_null]\n",
    "                for i in range(len(seqs_split_on_null[0]))]\n",
    "    # And return the binned list.\n",
    "    return bin_list\n",
    "\n",
    "def make_all_combinations(binned_parts,\n",
    "                          nucleotides_list = nukes):\n",
    "    \"\"\"\n",
    "    Given a list of sequence splits binned and a list of nucleotide strings\n",
    "    (default is nukes list defined above), generate a combination of a first\n",
    "    and second sequence part with a new nucleotide between them.\n",
    "    \n",
    "    This is a generator function. It does not commit each combination to memory.\n",
    "    Rather, it generates each combination and returns it, then continues once\n",
    "    other processes have completed.\n",
    "    \n",
    "    This function is kind of slow, but it should create all combinations of\n",
    "    two lists of strings separated by a new nucleotide.\n",
    "    \"\"\"\n",
    "    # Assure the inputs are all good\n",
    "    assert type(binned_parts) == list, \"The binned_parts argument should be a list...\"\n",
    "    for subbin in binned_parts:\n",
    "        assert type(subbin) == list, 'The bins in binned_parts should also be lists...'\n",
    "        for seq in subbin:\n",
    "            assert type(seq) == str, \"Each motif partition should be a str type...\"\n",
    "    # Initialize the current_combo string. This holds the current combination of\n",
    "    # part_a + N + part_b\n",
    "    current_combo = \"\"\n",
    "    # Initialize the seen list. This will hold all of the combinations that we have\n",
    "    # already come across, thus avoiding redundancy.\n",
    "    seen = []\n",
    "    # Loop over the number of motifs in the zeroeth bin\n",
    "    for i in range(len(binned_parts[0])):\n",
    "        # Loop over the number of motifs in the first bin\n",
    "        for j in range(len(binned_parts[1])):\n",
    "            # Loop over the nucleotides in the nucleotide list\n",
    "            for nucleotide in nucleotides_list:\n",
    "                # If the nucleotide in the list is not N\n",
    "                if nucleotide.upper() != \"N\":\n",
    "                    # Initialize the current combo.\n",
    "                    current_combo = f\"{binned_parts[0][i]}{nucleotide}{binned_parts[1][j]}\"\n",
    "                    # If the current combo is not in the seen list yet,\n",
    "                    if current_combo not in seen:\n",
    "                        # Then yield (return and wait).\n",
    "                        yield current_combo\n",
    "                        # Once the function resumes, add the current combo to the seen list\n",
    "                        seen.append(current_combo)\n",
    "                    # If the current combo is in the seen list\n",
    "                    else:\n",
    "                        # Then just continue, we don't need this one.\n",
    "                        continue\n",
    "\n",
    "def wrap_all_combinations(binned_parts,\n",
    "                          nucleotides_list = nukes):\n",
    "    \"\"\"\n",
    "    Given a list of sequence splits binned and a list of nucleotide strings\n",
    "    (default is nukes list defined above), return a list of all possible\n",
    "    combinations of the binned parts with all nucleotides.\n",
    "    \n",
    "    This function will iterate throught the bins in binned_parts and:\n",
    "    \n",
    "    1.) combine bins [0] and [1] using make_all_combinations()\n",
    "    \n",
    "    2.) Check if there are other combinations to be made\n",
    "    \n",
    "        2a.) If not, then return those combinations.\n",
    "        2b.) Otherwise, delete bin [0] and make bin[1] equal to the result\n",
    "             of combining bins [0] and [1], then try again. \n",
    "    \"\"\"\n",
    "    # Assure the inputs are all good\n",
    "    assert type(binned_parts) == list, \"The binned_parts argument should be a list...\"\n",
    "    for subbin in binned_parts:\n",
    "        assert type(subbin) == list, 'The bins in binned_parts should also be lists...'\n",
    "        for seq in subbin:\n",
    "            assert type(seq) == str, \"Each motif partition should be a str type...\"\n",
    "    # Get the number of bins in binned_parts\n",
    "    looper = len(binned_parts)\n",
    "    # Loop over the number of bins in binned parts\n",
    "    for i in range(looper):\n",
    "        # Use make_all_combinations to generate a list of combinations from the\n",
    "        # zeroeth and the first bins\n",
    "        uniq_combos = list( make_all_combinations(binned_parts, nucleotides_list = nukes))\n",
    "        # If there are only two bins in the binned_parts list\n",
    "        if binned_parts[2:] == []:\n",
    "            # Then return the uniq_combos list, you've made all the combinations!!\n",
    "            return uniq_combos\n",
    "        # Otherwise,\n",
    "        else:\n",
    "            # There are still more things to be combined. First, delete the zeroeth\n",
    "            # bin as it has already been used.\n",
    "            del binned_parts[0]\n",
    "            # Now what was the first bin is the zeroeth bin in binned parts. Since\n",
    "            # we now need to make all combinations of uniq_combos with binned_parts[1],\n",
    "            # reassign binned_parts[0] with uniq_combos. \n",
    "            binned_parts[0] = uniq_combos\n",
    "                \n",
    "def get_reversals(unique_combinations):\n",
    "    \"\"\"\n",
    "    Given a list of uniquely combined motif parts, return the list\n",
    "    in the reverse order.\n",
    "    \"\"\"\n",
    "    # Assure the input is all good\n",
    "    assert type(unique_combinations) == list, \"The unique_combinations argument must be a list...\"\n",
    "    # Use list comprehension with the reverse_a_str() function to generate alist\n",
    "    # of all strings in reverse order\n",
    "    reversals = [reverse_a_str(item) for item in unique_combinations]\n",
    "    # Return the list of reversed strings.\n",
    "    return reversals\n",
    "\n",
    "def combine_reversals_and_clean(unique_combinations,\n",
    "                                unique_reversals):\n",
    "    \"\"\"\n",
    "    Given two lists, return a combined list of these lists with only unique elements\n",
    "    \"\"\"\n",
    "    # Get the combined list of the two lists\n",
    "    total = unique_combinations + unique_reversals\n",
    "    # make the list into a set, and then back into a list.\n",
    "    total = list(set(total))\n",
    "    # Return the list\n",
    "    return total\n",
    "\n",
    "def format_parted_motifs(motif_list,\n",
    "                         partition_sites,\n",
    "                         minus = False):\n",
    "    \"\"\"\n",
    "    Given a motif_list, a list of sites to partition on, and\n",
    "    whether or not these sequences are for the minus strand\n",
    "    (default is False), return a list of all combinaitons of\n",
    "    the motifs.\n",
    "    \"\"\"\n",
    "    assert minus == True or minus == False, \"Only boolean values are accepted for named input minus\"\n",
    "    # The assertion statements for each input are included\n",
    "    # in the functions used in this function.\n",
    "    #\n",
    "    # Use partition_on_unassigned_nucs() to get hte parittion list\n",
    "    parted_list = partition_on_unassigned_nucs(motif_list,\n",
    "                                               partition_sites)\n",
    "    # Use bin_the_parts() to bin the parted motifs\n",
    "    binned_parts = bin_the_parts(parted_list)\n",
    "    # Use wrap_all_combinations() to get all combinations\n",
    "    # of the motif parts\n",
    "    all_motif_combos = wrap_all_combinations(binned_parts)\n",
    "    # If these motifs are minus strand motifs\n",
    "    if minus == True:\n",
    "        # Then use get_reversals to reverse the nucleotide\n",
    "        # sequences\n",
    "        all_motif_combos = get_reversals(all_motif_combos)\n",
    "    return all_motif_combos\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#    Functions for working with peak files\n",
    "\n",
    "def get_peak_regions(peakfile,\n",
    "                     extension,\n",
    "                     delimiter):\n",
    "    \"\"\"\n",
    "    Given the name of a peakfile, the extension for the\n",
    "    peak file, and a delimiter for the data in the peak\n",
    "    file, return a dictionary with keys as chromosome regions\n",
    "    and values as lists of (region_start, region_end) tuples\n",
    "    \"\"\"\n",
    "    # Make sure the file exists and what not\n",
    "    assert os.path.exists(peakfile), \"The given peak file does not exits\"\n",
    "    assert extension in [\"narrowPeak\", \"xls\"], \"The peak file should be an excel file or a narrowpeak file from MACS3\"\n",
    "    # Use the global peakfile_formats dictionary for formatting\n",
    "    global peakfile_formats\n",
    "    # The values in the peakfile_formats dictionary are the columns\n",
    "    # (math counting) of the desired information. Use list comprehension\n",
    "    # do get these values (minus 1 for computer counting)\n",
    "    columns = [int(value)-1 for key,value in peakfile_formats[extension].items()]\n",
    "    # and sort the columns in ascending order\n",
    "    columns = sorted(columns)\n",
    "    # Initialize the chromosome regions dictionary\n",
    "    chrom_regions = {}\n",
    "    # Open and read the peak file\n",
    "    with open(peakfile, 'r') as f:\n",
    "        # Use list comprehension to get a list of the lines,\n",
    "        # keeping only the information from the columns\n",
    "        # of interest.\n",
    "        try:\n",
    "            peak_regions = [[line.split(delimiter)[i] for i in columns]for line in f]\n",
    "        except:\n",
    "            raise ValueError(f\"Invalid delimiter: {delimiter} for this file type\")\n",
    "        # Once the list is attained, close the file\n",
    "        f.close()\n",
    "    # Next, loop over the sublists in the peak_regions list\n",
    "    for sublist in peak_regions:\n",
    "        # The zeroeth element of the sublist is the chromosome\n",
    "        # identifier. If this not already in the chrom_regions\n",
    "        # dictionary\n",
    "        if sublist[0] not in chrom_regions.keys():\n",
    "            # Then initialize this region inthe dictionary\n",
    "            chrom_regions[sublist[0]] = [sublist[1:]]\n",
    "        # Or if the region is already a key in the dictionary\n",
    "        elif sublist[0] in chrom_regions.keys():\n",
    "            # Check to see if the specific region is in the\n",
    "            # dictionary list already\n",
    "            if sublist[1:] in chrom_regions[sublist[0]]:\n",
    "                # If so, then continue\n",
    "                continue\n",
    "            # Otherwise\n",
    "            else:\n",
    "                # Add this new region to the dictionary\n",
    "                chrom_regions[sublist[0]].append(sublist[1:])\n",
    "    # Once the regions have been parsed, return the chrom_regions dictionary\n",
    "    return chrom_regions\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#    Finding the region sequences in a fasta file\n",
    "\n",
    "def check_next_region(nuc_count,\n",
    "                      peak_region_dict,\n",
    "                      chromosome,\n",
    "                      region_counter):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function for read_and_parse_fasta()\n",
    "    \n",
    "    Given: The current nucleotide count\n",
    "           A peak_region_dict (dictionary)\n",
    "           the current chromosome\n",
    "           the current region within that chromosome\n",
    "           \n",
    "    Return: True if the next_region starts in the same region\n",
    "            thatthe current region ends in\n",
    "            \n",
    "            False otherwise\n",
    "    \"\"\"\n",
    "    # No assertions here: These arguments are all passed in\n",
    "    # from the read_and_parse_fasta() function.\n",
    "    # The next region index in the list is the current region\n",
    "    # plus 1\n",
    "    next_region = region_counter + 1\n",
    "    # If the next region index is outside of the size of the list\n",
    "    if next_region >= len(peak_region_dict[chromosome]):\n",
    "        # Then return False, there is not a region at this index\n",
    "        return False\n",
    "    # Or if the next region is the same as the current region\n",
    "    elif peak_region_dict[chromosome][next_region] == peak_region_dict[chromosome][region_counter]:\n",
    "        # Then return False\n",
    "        return False\n",
    "    # If False hasn't been returned yet, then get the region front\n",
    "    # and the region end integers\n",
    "    region_front = int(peak_region_dict[chromosome][next_region][0])\n",
    "    region_end = int(peak_region_dict[chromosome][next_region][1])\n",
    "    # If current nucleotide count is between the region parameters\n",
    "    if nuc_count >= region_front and nuc_count <= region_end:\n",
    "        # Then return True, we need nucleotides from this region\n",
    "        return True\n",
    "    # If not,\n",
    "    else:\n",
    "        # Then return False, the function can proceed\n",
    "        return False\n",
    "\n",
    "def read_and_parse_fasta(fasta_file,\n",
    "                         peak_region_dictionary):\n",
    "    \"\"\"\n",
    "    Given the name of a fasta file and a dictionary\n",
    "    containing peak region information, return\n",
    "    a dictionary with:\n",
    "    \n",
    "    keys: chromosomes/chromosome identifiers\n",
    "    \n",
    "    values: lists of tuples:\n",
    "            (region_start, region_end, fasta_sequence)\n",
    "    \"\"\"\n",
    "    # Assure that the inputs are good\n",
    "    assert os.path.exists(fasta_file), \"The FASTA file given as input does not exist...\"\n",
    "    assert type(peak_region_dictionary) == dict, \"The peak_region_dictionary should be of type dict\"\n",
    "    # Initialize the nucleotide count, the region count\n",
    "    # the fasta_sequence_dictionary, and the iteration count variables.\n",
    "    nucleotide_count = 0\n",
    "    region_count = 0\n",
    "    fasta_sequence_dict = {}\n",
    "    iter_count = 0\n",
    "    # Open the fasta file and read\n",
    "    with open(fasta_file, 'r') as f:\n",
    "        # Initialize the overlap variable. True tells the function\n",
    "        # not to move on from the current line and to get more\n",
    "        # sequences from that line.\n",
    "        overlap = False\n",
    "        # Initialize the go variable. This tells the while loop to continue\n",
    "        go = True\n",
    "        # Initialize the current chromosome string, the current sequence\n",
    "        # string and the last region list.\n",
    "        current_chromosome = \"\"\n",
    "        current_sequence = \"\"\n",
    "        last_region = []\n",
    "        # While the go variable is true, continue looping.\n",
    "        while go:\n",
    "            # Add one to the iteration count.\n",
    "            iter_count +=1\n",
    "            # If the overlap variable is False,\n",
    "            if overlap == False:\n",
    "                # Read the line and strip the newline character\n",
    "                line = f.readline().strip()\n",
    "            # Next, try to get the zeroeth element of the line\n",
    "            try:\n",
    "                line[0]\n",
    "            # If this fails, then set go to False. The line is empty and the\n",
    "            # file is therefore empty\n",
    "            except:\n",
    "                go = False\n",
    "            # If the line is not empty, then we need to check the format of the line\n",
    "            else:\n",
    "                # If the zeroeth element of the line is a carrot, then this line\n",
    "                # specifies a region in the FASTA file.\n",
    "                if line[0] == \">\":\n",
    "                    # Loop over the keys, values inthe peak_region_dictionary\n",
    "                    for key in peak_region_dictionary.keys():\n",
    "                        # The keys of the peak_region_dictionary are chromosome\n",
    "                        # identifiers. Thus, if the key is in the line\n",
    "                        if key in line:\n",
    "                            # Then set all of the following variables\n",
    "                            current_chromosome= key\n",
    "                            current_sequence = \"\"\n",
    "                            region_count = 0\n",
    "                            nucleotide_count = 0\n",
    "                            prev_line_len = 0\n",
    "                            # And initialize the fasta_seque3nce_dictionary with and\n",
    "                            # empty list at this key\n",
    "                            fasta_sequence_dict[key] = []\n",
    "                            # And and break :)\n",
    "                            break\n",
    "                # If the line does not have the carrot in it, then it is an actual\n",
    "                # sequence.\n",
    "                else:\n",
    "                    # Take the line and lower all the characters in it.\n",
    "                    line = line.lower()\n",
    "                    # If the overlap variable is False (boolean)\n",
    "                    if overlap == False:\n",
    "                        # Then increase the nucleotide count by the length of the line\n",
    "                        # since this is a new line\n",
    "                        nucleotide_count += len(line)\n",
    "                    # If the region_count is outside of the length of the list, then\n",
    "                    # we have exhausted all peak regions in this genomic region.\n",
    "                    if len(peak_region_dictionary[current_chromosome]) <= region_count:\n",
    "                        # Therefore, continue until we find a new region\n",
    "                        continue\n",
    "                    # Otherwise, we need to analyze the sequences for this genomic region\n",
    "                    # still.\n",
    "                    else:\n",
    "                        # Thus, we should get the region front and region end as integers (for comparisons)\n",
    "                        region_front = int(peak_region_dictionary[current_chromosome][region_count][0])\n",
    "                        region_end = int(peak_region_dictionary[current_chromosome][region_count][1])\n",
    "                        # and update the last region variable.\n",
    "                        last_region = peak_region_dictionary[current_chromosome][region_count]\n",
    "                    # Now we have checked the current region we are in, we need to see if the\n",
    "                    # nucleotide count for this region is within that region or not.\n",
    "                    if nucleotide_count < region_front:\n",
    "                        # If the nucleotide count is below the beginning of the region, then continue\n",
    "                        continue\n",
    "                    # Or if the nucleotide count is wihtin the current peak region\n",
    "                    elif nucleotide_count >= region_front and nucleotide_count <= region_end:\n",
    "                        # Then check to see if the current sequence has been initialized\n",
    "                        if current_sequence == \"\":\n",
    "                            # If it has not, then get the difference between the current\n",
    "                            # nucleotide count and the beginning of the region. This number\n",
    "                            # is the distance from the end of the line to the\n",
    "                            # beginning of the region.\n",
    "                            dist_from_beg = abs(nucleotide_count - region_front)\n",
    "                            # Next, check the boundary conditions. If the difference between\n",
    "                            # the nucleotide count and region front is zero\n",
    "                            if dist_from_beg == 0:\n",
    "                                # Then the sequence begins at the begininng of the next line.\n",
    "                                # so keep the current sequence as zero\n",
    "                                current_sequence = f\"\"\n",
    "                            # Or if the difference betweent he nucleotide count adn the beginning\n",
    "                            # of the region front is the same as the length of the line,\n",
    "                            elif dist_from_beg == len(line):\n",
    "                                # Then just initialize the current sequence with the entire line.\n",
    "                                current_sequence = f\"{line}\"\n",
    "                            # In any other case\n",
    "                            else:\n",
    "                                # Calculate the distance from the beginning of the line to\n",
    "                                # the region front\n",
    "                                dist_to_beg = len(line) - dist_from_beg\n",
    "                                # And start the current sequence at the nucleotide in that\n",
    "                                # position.\n",
    "                                current_sequence = f\"{line[dist_to_beg:]}\"\n",
    "                        # If the current sequence is not an empty string,\n",
    "                        else:\n",
    "                            # Then simply add the entire line to the current sequence.\n",
    "                            current_sequence = f\"{current_sequence}{line}\"\n",
    "                    # If the nucleotide count is outside of the region_end and the current\n",
    "                    # sequence is not empty\n",
    "                    elif nucleotide_count >= region_end and current_sequence != \"\":\n",
    "                        # Then calculate the distance from the nucleotide count to the\n",
    "                        # region end.\n",
    "                        dist_from_end = abs(nucleotide_count - region_end)\n",
    "                        # If this distance is zero\n",
    "                        if dist_from_end == 0:\n",
    "                            # Then don't add anything. This should have been taken care\n",
    "                            # of in the previous steps\n",
    "                            current_sequence= f\"{current_sequence}\"\n",
    "                        # In any other case\n",
    "                        else:\n",
    "                            # Get the distance from the beginning of the current line to the\n",
    "                            # end of the region\n",
    "                            dist_to_beg = len(line) - dist_from_end\n",
    "                            # And update the current sequence\n",
    "                            current_sequence= f\"{current_sequence}{line[:dist_to_beg]}\"\n",
    "                        # If the current sequence is not empty,\n",
    "                        if current_sequence != \"\":\n",
    "                            # Then update the fasta_sequence_dict with this peak region beginning and end,\n",
    "                            # as well as the sequence found in this loop\n",
    "                            fasta_sequence_dict[current_chromosome].append((peak_region_dictionary[current_chromosome][region_count][0],\n",
    "                                                                            peak_region_dictionary[current_chromosome][region_count][1],\n",
    "                                                                            current_sequence))\n",
    "                            # Then reset the current sequence\n",
    "                            current_sequence = \"\"\n",
    "                            # and increase the region count by 1\n",
    "                            region_count += 1\n",
    "                            # Check for overlap between this region and the next region\n",
    "                            overlap = check_next_region(nucleotide_count,\n",
    "                                                        peak_region_dictionary,\n",
    "                                                        current_chromosome,\n",
    "                                                        region_count)\n",
    "                            \n",
    "    # At the end of this huge loop, return the sequence dictionary\n",
    "    return fasta_sequence_dict\n",
    "\n",
    "\n",
    "def check_parsed_fastas(fasta_seq_dict):\n",
    "    \"\"\"\n",
    "    Given a fasta_sequence_dictionary, check to make sure the sequence\n",
    "    lengths match the theoretical length of the region and toss\n",
    "    the sequences that do not match.\n",
    "    \"\"\"\n",
    "    # Assure the inputs are formatted properly\n",
    "    assert type(fasta_seq_dict) == dict, \"The fasta sequence dictionary should have type dict...\"\n",
    "    for key, value in fasta_seq_dict.items():\n",
    "        assert type(value) == list, \"The dictionary should have list values...\"\n",
    "        for item in value:\n",
    "            assert type(item) == tuple, \"The lists should all have tuples in them...\"\n",
    "            assert len(item) == 3, \"The tuples should all have 3 elements...\"\n",
    "    \n",
    "    # Initialize the variables for total number of sequences found,\n",
    "    # total number of sequences kept and total tossed\n",
    "    total = 0\n",
    "    total_kept = 0\n",
    "    total_tossed = 0\n",
    "    # Initialize a list of keys (chromosome regions) that are\n",
    "    # tossed because they are empty\n",
    "    keys_to_toss = []\n",
    "    # Loop over the keys and values in the fasta_seq_dict\n",
    "    for key, value in fasta_seq_dict.items():\n",
    "        # Initialize a list of indices to remove, if they fail\n",
    "        # the test\n",
    "        remove_indices = []\n",
    "        # Loop over each sublist in the current dict value\n",
    "        for sublist in value:\n",
    "            # If the length of the sequence and the theoretical distance\n",
    "            # are different, then tell the user\n",
    "            if int(sublist[1]) - int(sublist[0]) != len(sublist[2]):\n",
    "                print(f\"Something exploded while extracting the following FASTA sequence:\\n\")\n",
    "                print(f\"Chromosome: {key}\\t Sequence Start: {sublist[0]}\\t Sequence End: {sublist[1]}\")\n",
    "                print(f\"Extracted Sequence Length: {len(sublist[2])}\\t Theoretical Length: {int(sublist[1]) - int(sublist[0])}\\n\")\n",
    "                print(f\"This sequence will be omitted for the remainder of the program. \\n\")\n",
    "                # Get the index for these values\n",
    "                remove_indices.append(value.index(sublist))\n",
    "                # And increase the tossed count by one\n",
    "                total_tossed += 1\n",
    "            # Otherwise\n",
    "            else:\n",
    "                # Increase the kept count by 1\n",
    "                total_kept += 1\n",
    "            # Regardless, increase the total count by one\n",
    "            total += 1\n",
    "        # Once this has ceased, sort the removal indices in\n",
    "        # reverse order\n",
    "        remove_indices= sorted(remove_indices, reverse = True)\n",
    "        # Loop over the indices\n",
    "        for index in remove_indices:\n",
    "            # And remove them in reverse order\n",
    "            del value[index]\n",
    "            if fasta_seq_dict[key] == []:\n",
    "                # If the value is now empty, add the key to\n",
    "                # the keys_to_toss list\n",
    "                keys_to_toss.append(key)\n",
    "    # Loop over the keys and values in the keys_to_toss\n",
    "    for key in keys_to_toss:\n",
    "        # and delete those keys\n",
    "        del fasta_seq_dict[key]\n",
    "    # Then tell the users the results\n",
    "    print(f\"FASTA sequences checked for: Sequence Length matching the Theoretical Length.\")\n",
    "    print(f\"Total sequences found:   {total}\")\n",
    "    print(f\"Total sequences kept:    {total_kept}\")\n",
    "    print(f\"Total sequences tossed:  {total_tossed}\\n\")\n",
    "    if keys_to_toss != []:\n",
    "        print(f\"The following keys were removed because tossing sequences resulted in empty lists:\")\n",
    "        \n",
    "        for key in keys_to_toss:\n",
    "            print(f\"{key}\")\n",
    "    print(\"Proceeding with the remainder of the program :)\")\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#\n",
    "\n",
    "def true_false_fastas_with_binding_seqs(possible_binding_motifs,\n",
    "                                        fasta_seq_dict):\n",
    "    \"\"\"\n",
    "    Given a list of possible binding motifs and a fasta sequence\n",
    "    dictionary, return two dictionaries:\n",
    "    \n",
    "    The true_dict holds all sequences for which there was a match\n",
    "    between a possible binding motif and a fasta sequence dictionary\n",
    "    \n",
    "    The false_dict holds all sequences for which no match was found.\n",
    "    \"\"\"\n",
    "    # Assure that all of the inputs are formatted properly\n",
    "    assert type(possible_binding_motifs) == list, \"Binding motifs should be in a list\"\n",
    "    for item in possible_binding_motifs:\n",
    "        assert type(item) == str, \"Binding motifs should be strings... How did you break this?\"\n",
    "    assert type(fasta_seq_dict) == dict, \"The fasta sequences should be in a dictionary\"\n",
    "    # Initialize the true_dict and false_dict\n",
    "    true_dict = {}\n",
    "    false_dict = {}\n",
    "    # Loop over the keys and values in the fasta_seq_dict\n",
    "    for key, value in fasta_seq_dict.items():\n",
    "        # Loop over the number of items in the value list\n",
    "        for i in range(len(value)):\n",
    "            # Initialize the updated_sequence and location variables\n",
    "            updated_sequence = \"\"\n",
    "            location = \"\"\n",
    "            # Loop over the motifs in the possible_binding_motifs list\n",
    "            for motif in possible_binding_motifs:\n",
    "                # IF there is no updated sequence and the motif is in the sequence\n",
    "                if updated_sequence == \"\" and motif.lower() in value[i][2]:\n",
    "                    # Then update the sequence and save it as the updated sequence\n",
    "                    updated_sequence = value[i][2].replace(motif.lower(), motif)\n",
    "                    # If the location is also empty\n",
    "                    if location == \"\":\n",
    "                        # Then update the location string with the motif and where the motif\n",
    "                        # is found in the sequence\n",
    "                        location = f\"{motif}:({updated_sequence.index(motif) + 1 + int(value[i][0])})\"\n",
    "                    # Otherwise, update the location\n",
    "                    else:\n",
    "                        # With the new information\n",
    "                        location = f\"{location},{motif}:({updated_sequence.index(motif) + 1 + int(value[i][0])})\"\n",
    "                # Or if the updated sequence has been identified and another motif is in that sequence\n",
    "                elif updated_sequence != \"\" and motif.lower() in updated_sequence:\n",
    "                    # Then again update the sequence\n",
    "                    updated_sequence = updated_sequence.replace(motif.lower(), motif)\n",
    "                    # And if the location is (for some reason) empty, update it\n",
    "                    if location == \"\":\n",
    "                        location = f\"{motif}:({updated_sequence.index(motif) + 1 + int(value[i][0])})\"\n",
    "                    # Or if the location is not empty, add this new location to it\n",
    "                    else:\n",
    "                        location = f\"{location},{motif}:({updated_sequence.index(motif) + 1 + int(value[i][0])})\"\n",
    "                # If the motif is not in the sequence, then continue\n",
    "                else:\n",
    "                    continue\n",
    "            # If the location and the updated_sequence variables are empty\n",
    "            if location ==\"\" and updated_sequence == \"\":\n",
    "                # Then this goes in the false dictionary. Check to see if the key\n",
    "                # already exists in the false dictionary\n",
    "                if key not in false_dict.keys():\n",
    "                    # If not, then initialize the value\n",
    "                    false_dict[key] = [(value[i][0], value[i][1], value[i][2], None, False)]\n",
    "                # If so, then simply add the value\n",
    "                else:\n",
    "                    false_dict[key].append((value[i][0], value[i][1], value[i][2], None, False))\n",
    "            # And if th elovation and updated sequence are not empty\n",
    "            else:\n",
    "                # Then this goes in the true dictionary. Again, check to see if the key\n",
    "                # is already in the dictionary\n",
    "                if key not in true_dict.keys():\n",
    "                    # If not, initialize this list\n",
    "                    true_dict[key] = [(value[i][0], value[i][1], updated_sequence, location, True)]\n",
    "                # And if so, add this sequence to the list.\n",
    "                else:\n",
    "                    true_dict[key].append((value[i][0], value[i][1], updated_sequence, location, True))\n",
    "    # In the end, return the true and false dictionaries.\n",
    "    return true_dict, false_dict\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#        Functions for generating lines for file writing\n",
    "\n",
    "def fasta_dict_to_lines(fasta_seq_dict,\n",
    "                        tf_name=None):\n",
    "    \"\"\"\n",
    "    Given a fasta sequence dictionary and a transcription factor\n",
    "    name (default None), return a list of lines formatted\n",
    "    for FASTA files\n",
    "    \"\"\"\n",
    "    # If the fasta_seq_dict is empty, then return an empty list\n",
    "    if fasta_seq_dict == {}:\n",
    "        return []\n",
    "    # Otherwise, initialize the lines list\n",
    "    lines = []\n",
    "    # Loop over the keys and values in the fasta sequence dict\n",
    "    for key, value in fasta_seq_dict.items():\n",
    "        # loop over the number of items in the value list\n",
    "        for i in range(len(value)):\n",
    "            # If the sequence in the ith element of value is\n",
    "            # empty, then continue\n",
    "            if value[i][2] == \"\":\n",
    "                continue\n",
    "            # Otherwise\n",
    "            else:\n",
    "                # Add a newline character every 80 characters\n",
    "                sequence = add_newline_every_x_chars(value[i][2])\n",
    "                # If there was no TF name given, then just make the\n",
    "                # line have the chrom, the region start and end\n",
    "                if tf_name == None:\n",
    "                    newline = f\">{key}\\tregion:{value[i][0]}-{value[i][1]}\\n{sequence}\\n\"\n",
    "                # If a TF name was given, then use that information\n",
    "                # in the line generation\n",
    "                else:\n",
    "                    newline = f\">{key}\\tregion:{value[i][0]}-{value[i][1]}\\tpossible {tf_name} binding elements:{value[i][3]}\\n{sequence}\\n\"\n",
    "                # and add this string to the lines list\n",
    "                lines.append(newline)\n",
    "    # At the end, return the lines list.\n",
    "    return lines\n",
    "\n",
    "def combine_true_false_seq_lines(true_fasta_dict,\n",
    "                                 false_fasta_dict,\n",
    "                                 tf_name=\"TF\"):\n",
    "    \"\"\"\n",
    "    Given a true and false fasta dictionary pair and a transcription\n",
    "    factor name, return a list of lines to write with the\n",
    "    true lines first\n",
    "    \"\"\"\n",
    "    assert type(true_fasta_dict) == dict, \"true_fasta_dict should be of type 'dict'\"\n",
    "    assert type(false_fasta_dict) == dict, \"false_fasta_dict should be of type 'dict'\"\n",
    "    # Use the fasta_dict_to_lines() to get true lines\n",
    "    true_lines = fasta_dict_to_lines(true_fasta_dict, tf_name)\n",
    "    # Use the fasta_dict_to_lines() to get false lines\n",
    "    false_lines = fasta_dict_to_lines(false_fasta_dict, tf_name)\n",
    "    # If both lists are empty, raise a type error and exit\n",
    "    if true_lines == [] and false_lines == []:\n",
    "        raise TypeError(f\"Something exploded, and no sequences are available to write to a file..\")\n",
    "    # Otherwise, combine the lists and return that list\n",
    "    else:\n",
    "        lines_to_write = true_lines + false_lines\n",
    "        return lines_to_write\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#\n",
    "\n",
    "def write_output_file(lines_to_write,\n",
    "                      output_filename = \"peak_sequences.fasta\"):\n",
    "    \"\"\"\n",
    "    Given a list of lines to write and an output file name,\n",
    "    write a file!\n",
    "    \"\"\"\n",
    "    # Open the file with the writing tag\n",
    "    with open(output_filename, 'w') as f:\n",
    "        # Use the writelines method to write the lines\n",
    "        f.writelines(lines_to_write)\n",
    "        # close the file\n",
    "        f.close()\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#        Getting & Writing a Fasta file with binding motifs\n",
    "    \n",
    "def fasta_with_binding_motifs(sites_file, \n",
    "                              peak_file,\n",
    "                              genome_fasta,\n",
    "                              output_filename = \"peak_sequences.fasta\",\n",
    "                              use_partition = False,\n",
    "                              tf_name = \"TF\",\n",
    "                              delimiter = '\\t'):\n",
    "    print('Beginning:\\n')\n",
    "    print(f'Getting the annotated motifs from the file {sites_file}...\\n')\n",
    "    print(f\"Checking the annotated motifs for partition sites...\\n\")\n",
    "    annoted_motifs = get_partition_sites(sites_file, tf_name = tf_name)\n",
    "    assert len(annoted_motifs) == 1, \"Motifs of different lengths are present in your sites file... Please only have one motif length in a file...\"\n",
    "    print(f\"Getting all Plus and Minus strand sequences\\n\")\n",
    "    all_plus, all_minus = minus_to_plus(annoted_motifs[0][0])\n",
    "    if annoted_motifs[0][1] != [] and use_partition == True:\n",
    "        print(f\"An equally likely nucleotide position was found! Getting all possible sequences...\\n\")\n",
    "        all_plus = format_parted_motifs(all_plus, annoted_motifs[0][1], minus = False)\n",
    "        all_minus = format_parted_motifs(all_minus, annoted_motifs[0][1], minus = True)\n",
    "        all_motifs = combine_reversals_and_clean(all_plus,\n",
    "                                                 all_minus)\n",
    "        del all_plus\n",
    "        del all_minus\n",
    "        del annoted_motifs\n",
    "    else:\n",
    "        print(f\"No equally likely nucleotides were found. Proceeding using original sequences...\\n\")\n",
    "        all_minus = get_reversals(all_minus)\n",
    "        all_motifs = combine_reversals_and_clean(all_plus,\n",
    "                                                 all_minus)\n",
    "        del all_plus\n",
    "        del all_minus\n",
    "        del annoted_motifs\n",
    "    peak_extension = peak_file.split('.')[-1]\n",
    "    print(f'Gathering peak regions from {peak_file}...\\n')\n",
    "    peak_regions_dict = get_peak_regions(peak_file, peak_extension, delimiter)\n",
    "    print(f\"Finding the genomic sequences corresponding to peak regions...\\n\")\n",
    "    peak_sequence_dict = read_and_parse_fasta(genome_fasta, peak_regions_dict)\n",
    "    del peak_regions_dict\n",
    "    print(f\"Checking the sequences for consistency...\\n\")\n",
    "    check_parsed_fastas(peak_sequence_dict)\n",
    "    print(f\"\\nMapping motifs to the sequences found...\\n\")\n",
    "    true_sites_dict, false_sites_dict = true_false_fastas_with_binding_seqs(all_motifs,\n",
    "                                                                            peak_sequence_dict)\n",
    "    del all_motifs\n",
    "    del peak_sequence_dict\n",
    "    print(f\"Creating the lines for the FASTA file...\\n\")\n",
    "    lines = combine_true_false_seq_lines(true_sites_dict,\n",
    "                                         false_sites_dict,\n",
    "                                         tf_name=tf_name)\n",
    "    del true_sites_dict\n",
    "    del false_sites_dict\n",
    "    print(f\"Writing the FASTA file...\\n\")\n",
    "    write_output_file(lines, output_filename=f\"{os.path.split(os.path.realpath(peak_file))[0]}/{output_filename}\")\n",
    "    del lines\n",
    "    print(f\"Done! The file can be found in {os.path.dirname(peak_file)}...\")\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#\n",
    "    \n",
    "def fasta_without_binding_motifs(peak_file,\n",
    "                                 genome_file,\n",
    "                                 output_filename = \"peak_sequences.fasta\",\n",
    "                                 delimiter = '\\t'):\n",
    "    \"\"\"\n",
    "    Given a peak file, a genome_file (fasta format), an output filename, and delimiter,\n",
    "    find the peak region sequences and write them to a fasta file.\n",
    "    \"\"\"\n",
    "    peak_extension = peak_file.split('.')[-1]\n",
    "    peak_regions_dict = get_peak_regions(peak_file, peak_extension, delimiter)\n",
    "    peak_sequence_dict = read_and_parse_fasta(genome_fasta, peak_regions_dict)\n",
    "    del peak_regions_dict\n",
    "    check_parsed_fastas(peak_sequence_dict)\n",
    "    lines = fasta_dict_to_lines(peak_sequence_dict, tf_name = None)\n",
    "    del peak_sequence_dict\n",
    "    write_output_file(lines, output_filename = output_filename)\n",
    "    del lines\n",
    "    print('done')\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#########################################################################\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
